# 용어정리
## ETCD
ETCD는 간단하고, 보안성있고 빠른 신뢰할 수 있는 분산 키-값 저장소이다.

### k8s에서 ETCD
ETCD 데이터 저장소는 클러스터 내용들을 저장한다. 예를들면, nodes, pods, configs, secrets, accounts, roles, bindings 등등과 같은 데이터를 저장한다.  
`kubectl`을 실행할 때 얻는 모든 정보들은 ETCD 서버로 부터 가져오게 된다.


## 수동으로 설치하는 과정
Master Node
* etcd 설치 `wget -q --https-only "https://github.com/coreos/etcd/releases/download/v3.3.9/etcd-v3.3.9-linux-amd64.tar.gz"`
* kube-api server 설치 `wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-apiserver`
* kube-controller-manager `wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-controller-manager`
* kube-scheduler `wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-scheduler`

Worker Node
* kubelet 설치 `wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubelet`
## 클러스터 아키텍처
### 컨트롤 플레인
클러스터의 두뇌 역할, 컨테이너 스케줄링, 서비스 관리, API 요청하기  
컨트롤 플레인 컴포넌트는 클러스너 내 마스터 노드에서 실행
![k8s architecture](./components-of-kubernetes.svg)
> https://kubernetes.io/ko/docs/concepts/overview/components/  

**kube-apiserver**
- 컨트롤 플레인의 프론트엔드 서버로 API 요청 처리
- 쿠버네티스 API 서버의 주요 구현은 [kube-apiserver](https://kubernetes.io/docs/reference/generated/kube-apiserver/)이다.
- kuber-apiserver는 수평으로 확장 되도록 디자인 되었다.
- 즉, 더 많은 인스턴스를 배포해서 확장할 수 있다.
- 여러 kube-apiserver 인스턴스를 실행하고, 인스턴스간의 트래픽을 균형있게 조절할 수 있다.

**etcd**
- 어떤 노드가 존재하고 클러스터에 어떤 리소스가 존재하는지와 같은 k8s와 관련된 모든 정보를 저장하는 DB
- 일관성, 고가용성 키-값 저장소
- k8s luster에서 etcd를 뒷단의 저장소로 사용한다면, 이 데이터를 백업하는 계획은 필수

**kube-scheduler**
- 새로 생성된 파드를 실행할 노드 결정
- 스케줄링 결정을 위해서 고려되는 요소는 리소스에 대한 개별 및 총체적 요구 사항, 하드웨어/소프트웨어/정책적 제약, 어피니티(affinity) 및 안티-어피니티(anti-affinity) 명세, 데이터 지역성, 워크로드-간 간섭, 데드라인을 포함한다.

**kube-controller-manager**
- 컨트롤러(API서버를 통해 클러스터의 공유된 상태를 감시하고, 현재 상태를 원하는 상태로 이행시키는 컨트롤 루프)를 구동하는 마스터 상의 컴포넌트
- 논리적으로, 각 컨트롤러는 개별 프로세스이지만, 복잡성을 낮추기 위해 모두 단일 바이너리로 컴파일되고 단일 프로세스 내에서 실행된다.
- 디플로이먼트와 같은 리소스 컨트롤러 관리
- 컨트롤러는 다음을 포함한다.
  - 노드 컨트롤러: 노드가 다운되었을 때 통지와 대응에 관한 책임을 가진다.
  - 레플리케이션 컨트롤러: 시스템의 모든 레플리케이션 컨트롤러 오브젝트에 대해 알맞은 수의 파드들을 유지시켜 주는 책임을 가진다.
  - 엔드포인트 컨트롤러: 엔드포인트 오브젝트를 채운다(즉, 서비스와 파드를 연결시킨다.)
  - 서비스 어카운트 & 토큰 컨트롤러: 새로운 네임스페이스에 대한 기본 계정과 API 접근 토큰을 생성한다

**cloud-controller-manager**
- 클라우드 기반 클러스터는 클라우드 공급자의 API에 연동하여 로드밸런서나 디스크 볼륨과 같은 자원 관리
- cloud-controller-manager는 클라우드 제공자 전용 컨트롤러만 실행한다 => 자신의 사내 또는 PC 내부의 학습 환경에서 쿠버네티스를 실행 중인 경우 클러스터에는 클라우드 컨트롤러 매니저가 없다.
- 다음 컨트롤러들은 클라우드 제공 사업자의 의존성을 가질 수 있다.
  - 노드 컨트롤러: 노드가 응답을 멈춘 후 클라우드 상에서 삭제되었는지 판별하기 위해 클라우드 제공 사업자에게 확인하는 것
  - 라우트 컨트롤러: 기본 클라우드 인프라에 경로를 구성하는 것
  - 서비스 컨트롤러: 클라우드 제공 사업자 로드밸런서를 생성, 업데이트 그리고 삭제하는 것

### 노드 컴포넌트
노드 컴포넌트는 동작 중인 파드를  유지시키고 쿠버네티스 런타임 환경을 제공하며, 모든 노드 상에서 동작한다.
**kubelet**
- 파드에서 컨테이너가 확실하게 동작하도록 관리
- kubelet은 다양한 메커니즘을 통해 파드 스펙 (PodSpec)의 집합을 받아서 컨테이너가 해당 파드 스펙에 따라 건강하게 동작하는 것을 확실히 한다.
- kubelet은 쿠버네티스를 통해 생성되지 않는 컨테이너는 관리하지 않는다.
- 노드에 예약된 워크로드를 실행하기 위해 컨테이너 런타임을 관리하고 상태를 모니터링

**kube-proxy**
- 각 노드에서 실행되는 네트워크 프록시로, 쿠버네티스의 서비스(네트워크 서비스로 파드 집합에서 실행중인 애플리케이션을 노출하는 방법) 개념의 구현부이다.
- kube-proxy는 노드의 네트워크 규칙을 유지 관리. 이 네트워크 규칙이 내부 네트워크 세션이나 클러스터 바깥에서 파드로 네트워크 통신을 할 수 있도록 해준다.
- kube-proxy는 운영 체제에서 가용한 패킷 필터링 계층이 있는 경우, 이를 사용한다. 그렇지 않으면, kube-proxy는 프래픽 자체를 포워드(forward)한다.
- 서로 다른 노드에 있는 파드간 통신이나 파드와 인터넷 사이의 네트워크 트래픽을 라우팅한다.

**컨테이너 런타임**
- 컨테이너 실행을 담당하는 소프트웨어
- 여러 컨테이너 런타임을 지원함. docker, containerd, CRI-O 그리고 kubernetes CRI(컨테이너 런타임 인터페이스)를 구현하는 모든 소프트웨어

## 애드온
애드온은 쿠버네티스 리소스 (데몬셋, 디플로이먼트 등)를 이용하여 클러스터 기능을 구현한다. 이들은 클러스터 단위의 기능을 제공하기 때문에 애드온에 대한 네임스페이스 리소스는 `kube-system` 네임스페이스에 속한다.
[전체 애드온 리스트](https://kubernetes.io/ko/docs/concepts/cluster-administration/addons/)  

**DNS**
- 여타 애드온들이 절대적으로 요구되지 않지만, 많은 예시에서 필요로 하기 때문에 모든 쿠버네티스 클러스터는 [클러스터DNS](https://kubernetes.io/ko/docs/concepts/services-networking/dns-pod-service/)를 갖추어야한다.
- 클러스터 DNS는 구성환경 내 다른 DNS 서버와 더불어, 쿠버네티스 서비스를 위해 DNS 레코드를 제공해주는 DNS 서버
- 쿠버네티스에 의해 구동되는 컨테이너는 DNS 검색에서 이 DNS 서버를 자동으로 포함함

**웹UI(대시보드)**
- [대시보드](https://kubernetes.io/ko/docs/tasks/access-application-cluster/web-ui-dashboard/)는 쿠버네티스 클러스터를 위한 범용의 웹 기반 UI다.

**컨테이너 리소스 모니터링**
- [컨테이너 리소스 모니터링](https://kubernetes.io/ko/docs/tasks/debug-application-cluster/resource-usage-monitoring/)은 중앙 데이터베이스 내의 컨테이너들에 대한 포괄적인 시계열 매트릭스를 기록하고 그 데이터를 열람하기 위한 UI를 제공해 준다.
 
**클러스터-레벨 로깅**
- [클러스터-레벨 로깅](https://kubernetes.io/ko/docs/concepts/cluster-administration/logging/) 메커니즘은 검색/ 열람 인터페이스와 함께 중앙 로그 저장소에 컨테이너 로그를 저장하는 책임

## 쿠버네티스 리소스
**디플로이먼트**
- pod 시작
- 프로그램이 실행 중인지 계속 확인, 정지될 경우 다시 시작

**레플리카셋**
- 동일한 파드 집합이나 레플리카 관리
- 오브젝트 자동 생성 / 처리

**쿠버네티스 스케줄러**
- 디플로이먼트가 파드를 생성하고 쿠버네티스는 요청된 파드를 실행
- 스케줄러는 이 과정을 책임짐
- 디플로이먼트가 관련된 레플리카 셋을 통해 새로운 레플리카가 필요하다고 결정하면, 쿠버네티스 데이터베이스에 파드 리소스를 직접 생성한다.
- 동시에 이 파드는 스케줄러 수신함과 같은 대기열에 추가.
- 스케줄러의 역할은 대기열에서 스케줄링 되지 않은 파드를 찾아 배치하고 실행할 노드를 찾는 것이다.
- 파드가 노드에 스케줄링되면 노드에서 실행중인 kubelet이 실제로 컨테이너를 실행한다.
- 파드를 삭제했을 때 상태 변화를 감지하고 새로운 파드로 교체하는 것은 kubelet이다.

| 용어  | 요약  |
|---|---|
| pod  | 쿠버네티스의 기본 작업 단위로 스케쥴링될 단일 컨테이너나 컨테이너 그룹  |
| Deployment  | 파드를 선언적으로 관리하는 고수준 쿠버네티스 리소스.  배포, 스케줄링, 업데이트 작업을 수행하며 필요하다면 파드 재시작  |
| Service | 쿠버네티스의 로드 밸런서나 프록시에 해당하며 IP 주소나 DNS 이름을 통해 트래픽을 일치하는 파드로 라우팅한다.  |
| 스케줄러 | 노드에서 아직 실행되지 않은 파드를 감시하고 적합한 노드를 찾은 다음 해당 노드의 kubelet이 파드를 실행하도록 지시, 주어진 파드를 어디에서 실행할지 결정|
|메니페스트|YAML 파일|
|kubectl|쿠버네티스와 상호작용하기 위한 주요 도구로 메니페스트를 적용하고, 리소스를 조회, 변경, 삭제하는 등의 많은 작업 수행 가능|
|헬름|쿠버네티스 패키지 매니저. 쿠버네티스 APP을 쉽게 구성하고 배포할 수 있게 해준다. 직접 YAML 파일을 관리할 필요 없이 하나의 값 세트 ( APP 이름이나 수신 포드와 같은 ) 템플릿을 세트를 사용하여 쿠버네티스 YAML 파일을 생성할 수 있다.|
