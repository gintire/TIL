# Ingress
Service VS Ingress

![ingress](../contents/ingress01.PNG)
위 같은 서비스가 있다고 가정하자.

* wear 이라는 pod가 있다고하고, POD가 사용하는 DB (MySQL)이 외부에 노출이 되지않는 ClusterIP로 서비스를 생성한다.
* 유저들이 어플리케이션에 접근하기위해서 38080 포트를 통해 외부와 통신 한다 (NodePort)
* 유저들은 http:// IP 를통해서 어플리케이션에 접근가능하다.


![ingress](../contents/ingress02.PNG) 
* 만약, 외부로 node의 IP를 노출하고 싶지않는다면 DNS를 사용한다
* 포트를 노출하고 싶지않는다면 proxy 서버를 앞에 두고, DNS가 proxy서버를 바라보고 80포트를 통해서 접근하게 한다.

![ingress](../contents/ingress03.PNG)
* GCP와 같은 public cloud environment에서 운영한다면, NodePort를 사용하지않고 LoadBalancer를 사용한다.
* LoadBalancer은 NodePort가 해야할 일을 동일하게 수행한다.
    * 서비스를 위한 높은 포트를 프로비져닝한다.
* 그러나 추가적으로 쿠버네티스도 GCP에 서비스를 위한 네트워크 로드 밸런서를 프로비저닝하게 요청한다.

![ingress](../contents/ingress04.PNG)
* GCP가 요청을 받으면 자동으로 모드 노드에 대한 서비스 포트에 트래픽을 라우트하게 로드 밸런서를 설정하고 이 정보를 쿠버네티스에 반환해준다.
* 로그 밸런서는 유저가 어플리케이션으로 접근할 수 있는 외부 IP를 제공한다.

![ingress](../contents/ingress05.PNG)
* 이 경우 DNS가 로드밸런서를 바라보고 있고 유저들은 URL (my-online-store.com)을 통해서 어플리케이션에 접근 가능하다.

* 회사가 커져서 다른 서비스도 운영하기 시작했다고 가정한다.
* 완전히 다른 새로운 어플리케이션을 만들었고, 예전의 어플리케이션은 /wear를 통해 접근하게 한다.
    * www.my-online-store.com/wear
    * www.my-online-store.com/watch
* 하지만 같은 클러스터 자원을 공유하려면 새로운 어플리케션을 분리된 디플로이먼트로 같은 클러스터에 배포해야한다.
